{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Descripción del notebook</h3>\n",
    "<p>Desarrollamos este script para poder procesar todas las imágenes que tenemos descargadas en nuestras carpetas y generar unos ficheros csv con todos los datos necesarios para realizar el entrenamiento y la validación de nuestro futuro modelo CNN</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46fb3301d8699bf5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Cargamos las librerias necesáreas</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "337daa82ad35a28d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from skimage import exposure\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers\n",
    "from skimage.transform import resize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pydicom.pixel_data_handlers import pillow_handler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90da83d30966931b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Cargamos las imágenes y etiquetas</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf595ec59c8c62f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images_and_labels(df, base_path, batch_size=100):\n",
    "    images_path = []\n",
    "    labels = []\n",
    "    paths = []  # Agrega una lista para almacenar las rutas completas\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        for _, row in df.iterrows():\n",
    "            print(\"*****Estoy en el load_images_and_labels*****\",_)\n",
    "            path_paciente = row['image file path']\n",
    "            image_path = os.path.join(base_path, path_paciente.split('/')[0])\n",
    "            image_path = image_path.replace(\"/\", \"\\\\\")\n",
    "            images_path.extend(search_images(image_path))\n",
    "\n",
    "        # Cargamos imágenes en paralelo\n",
    "        loaded_images = list(executor.map(load_image, images_path))\n",
    "\n",
    "        # Filtramos las imágenes que no pudieron ser cargadas\n",
    "        valid_indices = [i for i, img in enumerate(loaded_images) if img is not None]\n",
    "        loaded_images = [img for i, img in enumerate(loaded_images) if i in valid_indices]\n",
    "        paths = [path for i, path in enumerate(images_path) if i in valid_indices]\n",
    "\n",
    "        # Obtenemos las etiquetas de las imágenes válidas\n",
    "        labels = df['pathology'].apply(lambda x: 1 if 'MALIGNANT' in x else (2 if 'BENIGN' in x else (3 if 'BENIGN WITHOUT CALLBACK' in x else (4 if 'MALIGNANT WITHOUT CALLBACK' in x else 0))))\n",
    "        labels = labels.values.astype(np.float32)\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "    return np.array(loaded_images), labels, paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b49981523d77abd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Función que busca imagenes DICOM y que carga la imagen respectivamente</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bdf0ef865fa6e05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def search_images(ruta):\n",
    "    imagenes = []\n",
    "\n",
    "    # Buscamos archivos de imagen (dcm) en la ruta de origen y subdirectorios\n",
    "    for root, dirs, files in os.walk(ruta):\n",
    "\n",
    "        # Este if lo hacemos por como está estructurada la arquitectura de carpetas y dcm, si no está en la raíz que no lo coja.\n",
    "        # Previamente ya se ha realizado un copiado de todas las imagenes .dcm a la carpeta que nos interesa con un script\n",
    "        if(len(root.split(\"\\\\\")) <= 9):\n",
    "            for file in files:\n",
    "                if file.endswith('.dcm'):\n",
    "                    imagenes.append(os.path.join(root, file))\n",
    "\n",
    "    return imagenes\n",
    "\n",
    "def load_image(image_path):\n",
    "    # Para ver la matriz total declaramos estas opciones\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "    print(\"Cargando imagen\", image_path)\n",
    "\n",
    "    try:\n",
    "        ds = pydicom.dcmread(image_path)\n",
    "\n",
    "        # Configuramos PyDicom para que utilice el manejador pillow\n",
    "        pydicom.config.image_handlers = [pillow_handler]\n",
    "\n",
    "        image = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "        # Normalizamos los valores entre 0 y 1\n",
    "        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "        image = exposure.equalize_adapthist(image)\n",
    "        image_resized = resize(image, (128, 128), mode='reflect', anti_aliasing=True)\n",
    "\n",
    "        # Convertimos la imagen en escala de grises a imagen RGB\n",
    "        image_rgb = np.stack((image_resized,) * 3, axis=-1)\n",
    "\n",
    "        return image_rgb\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la imagen {image_path}: {e}\")\n",
    "        return None  # Retorna None para indicar que ha ocurrido un error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "984642ddb111e409"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Función que guarda todos los datos en un csv</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e02e68b5b834f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_to_csv(images, labels, paths, csv_filename):\n",
    "    # Concatenamos las imágenes en una matriz tridimensional\n",
    "    images_array = np.stack(images, axis=0)\n",
    "\n",
    "    # Creamos un DataFrame con las imágenes y etiquetas\n",
    "    df = pd.DataFrame({'Image': images_array.tolist(), 'Label': labels, 'Path': paths})\n",
    "\n",
    "    # Guardamos el DataFrame en un archivo CSV\n",
    "    df.to_csv(csv_filename, index=False, sep=';')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f80d8b2c482788e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p>Iniciamos el script definiendo la ruta base donde se encuentran las imágenes y cargamos los datos para generar los csv resultantes</p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb6ca7811382a645"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos la ruta base donde se encuentran las imágenes\n",
    "base_image_path = \"D:/Documentos/0.-Universidad Ingeniería Informática/TFG/proyecto/src/resources/CBIS-DDSM\"\n",
    "\n",
    "# Cargamos datos de cáncer de masa\n",
    "df_mass_train = pd.read_csv('./resources/csv/mass_case_description_train_set.csv')\n",
    "df_mass_test = pd.read_csv('./resources/csv/mass_case_description_test_set.csv')\n",
    "\n",
    "# Cargamos datos de cáncer de calcificación\n",
    "df_calc_train = pd.read_csv('./resources/csv/calc_case_description_train_set.csv')\n",
    "df_calc_test = pd.read_csv('./resources/csv/calc_case_description_test_set.csv')\n",
    "\n",
    "# Combinamos los datos de entrenamiento y prueba\n",
    "df_train = pd.concat([df_mass_train, df_calc_train], ignore_index=True)\n",
    "df_test = pd.concat([df_mass_test, df_calc_test], ignore_index=True)\n",
    "\n",
    "\n",
    "# Cargar imágenes y etiquetas de entrenamiento y prueba y guardarlas en csv\n",
    "X_train, y_train, paths_train = load_images_and_labels(df_train, base_image_path)\n",
    "csv_filenameTrain = 'resultadosXytrain.csv'\n",
    "save_to_csv(X_train, y_train, paths_train, csv_filenameTrain)\n",
    "\n",
    "X_test, y_test, paths_test = load_images_and_labels(df_test, base_image_path)\n",
    "csv_filenameTest = 'resultadosXytest.csv'\n",
    "save_to_csv(X_test, y_test, paths_test, csv_filenameTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
